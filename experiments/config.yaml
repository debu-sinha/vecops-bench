# VectorDB-Bench Experiment Configuration

experiment:
  name: "vectordb-bench-v1"
  description: "Production-oriented vector database benchmark"
  random_seed: 42

databases:
  pinecone:
    enabled: true
    config:
      api_key: "${PINECONE_API_KEY}"
      environment: "gcp-starter"
      index_type: "serverless"

  milvus:
    enabled: true
    config:
      host: "localhost"
      port: 19530
      deployment: "docker"

  qdrant:
    enabled: true
    config:
      host: "localhost"
      port: 6333
      deployment: "docker"

  pgvector:
    enabled: true
    config:
      host: "localhost"
      port: 5432
      database: "vectordb_bench"
      user: "postgres"

  chroma:
    enabled: true
    config:
      persist_directory: "./data/chroma"
      deployment: "local"

  weaviate:
    enabled: true
    config:
      host: "localhost"
      port: 8080
      deployment: "docker"

datasets:
  - name: "msmarco-passage"
    source: "beir"
    num_docs: 100000  # Subset for benchmarking
    dimensions: 768

  - name: "nfcorpus"
    source: "beir"
    num_docs: null  # Full dataset
    dimensions: 768

  - name: "scifact"
    source: "beir"
    num_docs: null
    dimensions: 768

embedding_model:
  name: "sentence-transformers/all-mpnet-base-v2"
  dimensions: 768
  batch_size: 32

benchmark:
  # Standard metrics
  recall_k: [1, 10, 100]
  num_queries: 1000
  qps_duration_seconds: 30

  # Production metrics
  cold_start_trials: 5
  filtered_search_enabled: true
  hybrid_search_enabled: true

  # Workload patterns
  workloads:
    - name: "uniform"
      description: "Uniform random queries"
      distribution: "uniform"

    - name: "bursty"
      description: "Bursty traffic pattern"
      distribution: "poisson"
      rate: 100

    - name: "skewed"
      description: "Zipfian query distribution"
      distribution: "zipf"
      alpha: 1.2

output:
  results_dir: "./results"
  save_latencies: true
  save_plots: true
  export_formats: ["json", "csv", "latex"]
